{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hairy-monitoring",
   "metadata": {},
   "source": [
    "## Installing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hungry-kazakhstan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.18.5 in d:\\anaconda\\lib\\site-packages (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U numpy==1.18.5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import concat\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "import keras\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import sklearn.model_selection\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-munich",
   "metadata": {},
   "source": [
    "Import dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "thirty-sleeve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>SO2.EST4</th>\n",
       "      <th>CO.EST4</th>\n",
       "      <th>NO.EST4</th>\n",
       "      <th>NO2.EST4</th>\n",
       "      <th>NOX.EST4</th>\n",
       "      <th>SO2EST35</th>\n",
       "      <th>COEST35</th>\n",
       "      <th>NOEST35</th>\n",
       "      <th>NO2EST35</th>\n",
       "      <th>NOXEST35</th>\n",
       "      <th>tmed</th>\n",
       "      <th>prec</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>presMax</th>\n",
       "      <th>presMin</th>\n",
       "      <th>Dia_semana</th>\n",
       "      <th>tipo</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>83</td>\n",
       "      <td>45</td>\n",
       "      <td>172</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>111</td>\n",
       "      <td>68</td>\n",
       "      <td>239</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>40</td>\n",
       "      <td>9518</td>\n",
       "      <td>9448</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>8.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>107</td>\n",
       "      <td>56</td>\n",
       "      <td>220</td>\n",
       "      <td>8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>98</td>\n",
       "      <td>54</td>\n",
       "      <td>205</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>40</td>\n",
       "      <td>9518</td>\n",
       "      <td>9448</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>101</td>\n",
       "      <td>54</td>\n",
       "      <td>209</td>\n",
       "      <td>9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>98</td>\n",
       "      <td>68</td>\n",
       "      <td>297</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>40</td>\n",
       "      <td>9518</td>\n",
       "      <td>9448</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>7.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>96</td>\n",
       "      <td>50</td>\n",
       "      <td>197</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>98</td>\n",
       "      <td>67</td>\n",
       "      <td>282</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>40</td>\n",
       "      <td>9518</td>\n",
       "      <td>9448</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>5.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 05:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>53</td>\n",
       "      <td>37</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>100</td>\n",
       "      <td>55</td>\n",
       "      <td>208</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>40</td>\n",
       "      <td>9518</td>\n",
       "      <td>9448</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fecha  SO2.EST4  CO.EST4  NO.EST4  NO2.EST4  NOX.EST4  \\\n",
       "0 2017-01-01 01:00:00         7      0.6       83        45       172   \n",
       "1 2017-01-01 02:00:00         6      0.6      107        56       220   \n",
       "2 2017-01-01 03:00:00         6      0.5      101        54       209   \n",
       "3 2017-01-01 04:00:00         6      0.5       96        50       197   \n",
       "4 2017-01-01 05:00:00         4      0.4       53        37       119   \n",
       "\n",
       "   SO2EST35  COEST35  NOEST35  NO2EST35  NOXEST35  tmed  prec  tmin  tmax  \\\n",
       "0        10      0.8      111        68       239    17   0.0    -6    40   \n",
       "1         8      0.7       98        54       205    17   0.0    -6    40   \n",
       "2         9      0.8       98        68       297    17   0.0    -6    40   \n",
       "3         7      0.7       98        67       282    17   0.0    -6    40   \n",
       "4         6      0.6      100        55       208    17   0.0    -6    40   \n",
       "\n",
       "   presMax  presMin Dia_semana tipo    O3  \n",
       "0     9518     9448          D    D  8.32  \n",
       "1     9518     9448          D    D  3.60  \n",
       "2     9518     9448          D    D  7.44  \n",
       "3     9518     9448          D    D  5.67  \n",
       "4     9518     9448          D    D  3.25  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('DatosPreprocesadosH.csv')\n",
    "data = data.loc[:, data.columns != 'Unnamed: 0']\n",
    "data['fecha'] = pd.to_datetime(data['fecha'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-airfare",
   "metadata": {},
   "source": [
    "Select neccesaries variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "american-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.iloc[:, 6:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-switzerland",
   "metadata": {},
   "source": [
    "Transform target variable in categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "infinite-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(dataset.shape[0]):\n",
    "    if (dataset.iloc[i,13] < 60):\n",
    "        dataset.iloc[i,13] = 0\n",
    "    elif (60 < dataset.iloc[i,13] < 120):\n",
    "        dataset.iloc[i,13] = 1\n",
    "    else:\n",
    "        dataset.iloc[i,13] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "passing-experience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26985\n",
      "10509\n",
      "570\n"
     ]
    }
   ],
   "source": [
    "print(list(dataset['O3']).count(0))\n",
    "print(list(dataset['O3']).count(1))\n",
    "print(list(dataset['O3']).count(2))\n",
    "# print(list(dataset['O3']).count(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-radical",
   "metadata": {},
   "source": [
    "Obtain values from dataset and create the series to supervised function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "personal-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = dataset.values\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-marine",
   "metadata": {},
   "source": [
    "Encoder categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "provincial-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = dataset.values\n",
    "encoder = LabelEncoder()\n",
    "values[:,11] = encoder.fit_transform(values[:,11])\n",
    "values[:,12] = encoder.fit_transform(values[:,12])\n",
    "values[:,13] = encoder.fit_transform(values[:,13])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-necklace",
   "metadata": {},
   "source": [
    "Scale variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "neural-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-omaha",
   "metadata": {},
   "source": [
    "Select for predict in the desired time in advance (24 hours). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "arranged-paris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-24)</th>\n",
       "      <th>var2(t-24)</th>\n",
       "      <th>var3(t-24)</th>\n",
       "      <th>var4(t-24)</th>\n",
       "      <th>var5(t-24)</th>\n",
       "      <th>var6(t-24)</th>\n",
       "      <th>var7(t-24)</th>\n",
       "      <th>var8(t-24)</th>\n",
       "      <th>var9(t-24)</th>\n",
       "      <th>var10(t-24)</th>\n",
       "      <th>...</th>\n",
       "      <th>var6(t-21)</th>\n",
       "      <th>var7(t-21)</th>\n",
       "      <th>var8(t-21)</th>\n",
       "      <th>var9(t-21)</th>\n",
       "      <th>var10(t-21)</th>\n",
       "      <th>var11(t-21)</th>\n",
       "      <th>var12(t-21)</th>\n",
       "      <th>var13(t-21)</th>\n",
       "      <th>var14(t-21)</th>\n",
       "      <th>o3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.917355</td>\n",
       "      <td>0.260536</td>\n",
       "      <td>0.497917</td>\n",
       "      <td>0.140884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206687</td>\n",
       "      <td>0.091584</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206687</td>\n",
       "      <td>0.091584</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.748744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.427083</td>\n",
       "      <td>0.140884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206687</td>\n",
       "      <td>0.091584</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206687</td>\n",
       "      <td>0.091584</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.748744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.260536</td>\n",
       "      <td>0.618750</td>\n",
       "      <td>0.140884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206687</td>\n",
       "      <td>0.091584</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206687</td>\n",
       "      <td>0.091584</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.748744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.256705</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.140884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206687</td>\n",
       "      <td>0.091584</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206687</td>\n",
       "      <td>0.091584</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.748744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.210728</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.140884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206687</td>\n",
       "      <td>0.091584</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206687</td>\n",
       "      <td>0.091584</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.748744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    var1(t-24)  var2(t-24)  var3(t-24)  var4(t-24)  var5(t-24)  var6(t-24)  \\\n",
       "24    0.192308        0.32    0.917355    0.260536    0.497917    0.140884   \n",
       "25    0.153846        0.28    0.809917    0.206897    0.427083    0.140884   \n",
       "26    0.173077        0.32    0.809917    0.260536    0.618750    0.140884   \n",
       "27    0.134615        0.28    0.809917    0.256705    0.587500    0.140884   \n",
       "28    0.115385        0.24    0.826446    0.210728    0.433333    0.140884   \n",
       "\n",
       "    var7(t-24)  var8(t-24)  var9(t-24)  var10(t-24)  ...  var6(t-21)  \\\n",
       "24         0.0    0.206687    0.091584     0.746867  ...    0.140884   \n",
       "25         0.0    0.206687    0.091584     0.746867  ...    0.140884   \n",
       "26         0.0    0.206687    0.091584     0.746867  ...    0.140884   \n",
       "27         0.0    0.206687    0.091584     0.746867  ...    0.140884   \n",
       "28         0.0    0.206687    0.091584     0.746867  ...    0.140884   \n",
       "\n",
       "    var7(t-21)  var8(t-21)  var9(t-21)  var10(t-21)  var11(t-21)  var12(t-21)  \\\n",
       "24         0.0    0.206687    0.091584     0.746867     0.748744          0.0   \n",
       "25         0.0    0.206687    0.091584     0.746867     0.748744          0.0   \n",
       "26         0.0    0.206687    0.091584     0.746867     0.748744          0.0   \n",
       "27         0.0    0.206687    0.091584     0.746867     0.748744          0.0   \n",
       "28         0.0    0.206687    0.091584     0.746867     0.748744          0.0   \n",
       "\n",
       "    var13(t-21)  var14(t-21)   o3  \n",
       "24          0.0          0.0  0.0  \n",
       "25          0.0          0.0  0.0  \n",
       "26          0.0          0.0  0.0  \n",
       "27          0.0          0.0  0.0  \n",
       "28          0.0          0.0  0.0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reformed = series_to_supervised(scaled,24)\n",
    "reformed=reformed.iloc[:,0:56]\n",
    "reformed['o3'] = dataset[\"O3\"]\n",
    "reformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-python",
   "metadata": {},
   "source": [
    "Divide dataset in trainning set and testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "reasonable-statistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 1, 56) (30000,) (8040, 1, 56) (8040,)\n"
     ]
    }
   ],
   "source": [
    "V = reformed.values\n",
    "train = V[:30000, :]\n",
    "test = V[30000:, :]\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "train_X = np.asarray(train_X).astype('float32')\n",
    "test_X = np.asarray(test_X).astype('float32')\n",
    "labelencoder = LabelEncoder()\n",
    "train_y = labelencoder.fit_transform(train_y)\n",
    "test_y = labelencoder.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-sunrise",
   "metadata": {},
   "source": [
    "### Deep Transformer Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-poster",
   "metadata": {},
   "source": [
    "Development of the deep transformer network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "floppy-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(train_y))\n",
    "input_shape = train_X.shape[1:]\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-4)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "owned-reynolds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 56)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-layer",
   "metadata": {},
   "source": [
    "Fit the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "brief-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=2,\n",
    "    num_heads=2,\n",
    "    ff_dim=1,\n",
    "    num_transformer_blocks=1,\n",
    "    mlp_units=[500],\n",
    "    mlp_dropout=0.2,\n",
    "    dropout=0.15,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-chester",
   "metadata": {},
   "source": [
    "Visualising the model in Netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "average-rebecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'model.h5' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8080)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 55660)\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\socketserver.py\", line 650, in process_request_thread\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"D:\\anaconda\\lib\\socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"D:\\anaconda\\lib\\socketserver.py\", line 720, in __init__\n",
      "    self.handle()\n",
      "  File \"D:\\anaconda\\lib\\http\\server.py\", line 427, in handle\n",
      "    self.handle_one_request()\n",
      "  File \"D:\\anaconda\\lib\\http\\server.py\", line 415, in handle_one_request\n",
      "    method()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\netron\\server.py\", line 108, in do_GET\n",
      "    self.handler()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\netron\\server.py\", line 106, in handler\n",
      "    self.wfile.write(buffer)\n",
      "  File \"D:\\anaconda\\lib\\socketserver.py\", line 799, in write\n",
      "    self._sock.sendall(b)\n",
      "ConnectionAbortedError: [WinError 10053] Se ha anulado una conexión establecida por el software en su equipo host\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pip install netron\n",
    "import netron\n",
    "model.save('model.h5')\n",
    "netron.start('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-pharmaceutical",
   "metadata": {},
   "source": [
    "Compile and summary the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-mobility",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(232323)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-buffalo",
   "metadata": {},
   "source": [
    "Set the callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(patience=12, restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-smoke",
   "metadata": {},
   "source": [
    "Proofs with hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-manhattan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = list()\n",
    "b = list()\n",
    "for k in range(3,20,3):\n",
    "    for j in range(3,20,3):\n",
    "        for f in range(5,30,5):\n",
    "            model = build_model(\n",
    "            input_shape,\n",
    "            head_size=k,\n",
    "            num_heads=j,\n",
    "            ff_dim=f,\n",
    "            num_transformer_blocks=1,\n",
    "            mlp_units=[5000],\n",
    "            mlp_dropout=0.2,\n",
    "            dropout=0.15,\n",
    "            )\n",
    "            tf.random.set_seed(232323)\n",
    "            model.compile(\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=\"adam\",\n",
    "                metrics=keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            )\n",
    "            model.summary()\n",
    "            tf.random.set_seed(3444)\n",
    "            model.fit(\n",
    "                train_X,\n",
    "                train_y,\n",
    "                validation_split = 0.02,\n",
    "                epochs=20,\n",
    "                batch_size=8,\n",
    "                callbacks=callbacks,\n",
    "            )\n",
    "\n",
    "            pred = model.predict(test_X)\n",
    "            predi = list()\n",
    "            for i in range(pred.shape[0]):\n",
    "                max_value = max(list(pred[i]))\n",
    "                max_index = list(pred[i]).index(max_value)\n",
    "                predi.append(max_index)\n",
    "            cm = confusion_matrix(test_y.reshape(test_X.shape[0]),predi)\n",
    "\n",
    "\n",
    "            acc=sklearn.metrics.accuracy_score(test_y.reshape(test_X.shape[0]),predi)\n",
    "            bac=sklearn.metrics.balanced_accuracy_score(test_y.reshape(test_X.shape[0]),predi)\n",
    "            a.append(acc)\n",
    "            b.append(bac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-pipeline",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = list()\n",
    "b = list()\n",
    "for _ in range(20):\n",
    "    tf.random.set_seed(3444)\n",
    "    model.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    validation_split = 0.1,\n",
    "    epochs=15,\n",
    "    batch_size=8,\n",
    "    callbacks=callbacks,\n",
    "    )\n",
    "    pred = model.predict(test_X)\n",
    "    predi = list()\n",
    "    for i in range(pred.shape[0]):\n",
    "        max_value = max(list(pred[i]))\n",
    "        max_index = list(pred[i]).index(max_value)\n",
    "        predi.append(max_index)\n",
    "    cm = confusion_matrix(test_y.reshape(test_X.shape[0]),predi)\n",
    "    cm\n",
    "    acc=sklearn.metrics.accuracy_score(test_y.reshape(test_X.shape[0]),predi)\n",
    "    bac=sklearn.metrics.balanced_accuracy_score(test_y.reshape(test_X.shape[0]),predi)\n",
    "    a.append(acc)\n",
    "    b.append(bac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-stylus",
   "metadata": {},
   "source": [
    "Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-nursing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_X,\n",
    "    train_y,\n",
    "    validation_split = 0.02,\n",
    "    epochs=35,\n",
    "    batch_size=8,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "pred = model.predict(test_X)\n",
    "predi = list()\n",
    "for i in range(pred.shape[0]):\n",
    "    max_value = max(list(pred[i]))\n",
    "    max_index = list(pred[i]).index(max_value)\n",
    "    predi.append(max_index)\n",
    "cm = confusion_matrix(test_y.reshape(test_X.shape[0]),predi)\n",
    "cm\n",
    "acc=sklearn.metrics.accuracy_score(test_y.reshape(test_X.shape[0]),predi)\n",
    "bac=sklearn.metrics.balanced_accuracy_score(test_y.reshape(test_X.shape[0]),predi)\n",
    "print(bac), print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-singapore",
   "metadata": {},
   "source": [
    "Make the predictions in testing set and print the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_X)\n",
    "predi = list()\n",
    "for i in range(pred.shape[0]):\n",
    "    max_value = max(list(pred[i]))\n",
    "    max_index = list(pred[i]).index(max_value)\n",
    "    predi.append(max_index)\n",
    "cm = confusion_matrix(test_y.reshape(test_X.shape[0]),predi)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-steal",
   "metadata": {},
   "source": [
    "Evaluate the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=sklearn.metrics.accuracy_score(test_y.reshape(test_X.shape[0]),predi)\n",
    "bac=sklearn.metrics.balanced_accuracy_score(test_y.reshape(test_X.shape[0]),predi)\n",
    "print(bac), print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-sister",
   "metadata": {},
   "source": [
    "### MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-automation",
   "metadata": {},
   "source": [
    "Reshape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-rating",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1 = train_X.reshape(train_X.shape[0],train_X.shape[2])\n",
    "train_X1 = np.asarray(train_X1).astype('float32')\n",
    "test_X1 = test_X.reshape(test_X.shape[0],test_X.shape[2])\n",
    "test_X1 = np.asarray(test_X1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-engineering",
   "metadata": {},
   "source": [
    "Development and compile the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-domestic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelmlp = Sequential()\n",
    "modelmlp.add(Dense(64, input_dim=test_X.shape[2], activation= 'relu'))\n",
    "modelmlp.add(Dense(64, activation='relu'))\n",
    "modelmlp.add(Dense(16, activation='relu'))\n",
    "modelmlp.add(Dense(8, activation='relu'))\n",
    "modelmlp.add(Dense(8, activation='relu'))\n",
    "# modelmlp.add(Dense(16, activation='relu'))\n",
    "modelmlp.add(Dense(3, activation='softmax'))\n",
    "modelmlp.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",metrics=[\"sparse_categorical_accuracy\"])\n",
    "print(modelmlp.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-liechtenstein",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-share",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(11111)\n",
    "modelmlp.fit(train_X1, train_y, batch_size=16, epochs=19, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-compact",
   "metadata": {},
   "source": [
    "Make the predictions in testing set and print the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "predmlp = modelmlp.predict(test_X.reshape(test_X.shape[0],test_X.shape[2]))\n",
    "predimlp = list()\n",
    "for i in range(predmlp.shape[0]):\n",
    "    max_value = max(list(predmlp[i]))\n",
    "    max_index = list(predmlp[i]).index(max_value)\n",
    "    predimlp.append(max_index)\n",
    "cmmlp = confusion_matrix(test_y.reshape(test_X.shape[0]),predimlp)\n",
    "cmmlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-sculpture",
   "metadata": {},
   "source": [
    "Evaluate the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "accmlp=sklearn.metrics.accuracy_score(test_y.reshape(test_X.shape[0]),predimlp)\n",
    "bacmlp=sklearn.metrics.balanced_accuracy_score(test_y.reshape(test_X.shape[0]),predimlp)\n",
    "print(bacmlp), print(accmlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-uncle",
   "metadata": {},
   "source": [
    "The entire process. 20 replications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-crisis",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X1 = train_X.reshape(train_X.shape[0],train_X.shape[2])\n",
    "train_X1 = np.asarray(train_X1).astype('float32')\n",
    "test_X1 = test_X.reshape(test_X.shape[0],test_X.shape[2])\n",
    "test_X1 = np.asarray(test_X1).astype('float32')\n",
    "a = list()\n",
    "b = list()\n",
    "for _ in range(20):\n",
    "    modelmlp = Sequential()\n",
    "    modelmlp.add(Dense(512, input_dim=test_X.shape[2], activation= 'relu'))\n",
    "    modelmlp.add(Dense(256, activation='relu'))\n",
    "    modelmlp.add(Dense(128, activation='relu'))\n",
    "    modelmlp.add(Dense(32, activation='relu'))\n",
    "    modelmlp.add(Dense(32, activation='relu'))\n",
    "    # modelmlp.add(Dense(16, activation='relu'))\n",
    "    modelmlp.add(Dense(3, activation='softmax'))\n",
    "    modelmlp.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",metrics=[\"sparse_categorical_accuracy\"])\n",
    "    print(modelmlp.summary())\n",
    "    modelmlp.fit(train_X1, train_y, batch_size=16, epochs=20, validation_split=0.1, verbose=1)\n",
    "    predmlp = modelmlp.predict(test_X.reshape(test_X.shape[0],test_X.shape[2]))\n",
    "    predimlp = list()\n",
    "    for i in range(predmlp.shape[0]):\n",
    "        max_value = max(list(predmlp[i]))\n",
    "        max_index = list(predmlp[i]).index(max_value)\n",
    "        predimlp.append(max_index)\n",
    "    cmmlp = confusion_matrix(test_y.reshape(test_X.shape[0]),predimlp)\n",
    "    accmlp=sklearn.metrics.accuracy_score(test_y.reshape(test_X.shape[0]),predimlp)\n",
    "    bacmlp=sklearn.metrics.balanced_accuracy_score(test_y.reshape(test_X.shape[0]),predimlp)\n",
    "    a.append(accmlp)\n",
    "    b.append(bacmlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-prerequisite",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-strengthening",
   "metadata": {},
   "source": [
    "Develop and train Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-clear",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf150 = RandomForestClassifier(n_estimators = 250)\n",
    "rf150.fit(train_X1, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-individual",
   "metadata": {},
   "source": [
    "Predictions and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-float",
   "metadata": {},
   "outputs": [],
   "source": [
    "predrf = rf150.predict(test_X.reshape(test_X.shape[0],test_X.shape[2]))\n",
    "cmrf = confusion_matrix(test_y.reshape(test_X.shape[0]),predrf)\n",
    "cmrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-string",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accrf=sklearn.metrics.accuracy_score(test_y.reshape(test_X.shape[0]),predrf)\n",
    "bacrf=sklearn.metrics.balanced_accuracy_score(test_y.reshape(test_X.shape[0]),predrf)\n",
    "print(bacrf), print(accrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-lithuania",
   "metadata": {},
   "source": [
    "The entire process. 20 replications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list()\n",
    "b = list()\n",
    "for _ in range(15):\n",
    "    rf150 = RandomForestClassifier(n_estimators = 250)\n",
    "    rf150.fit(train_X1, train_y)\n",
    "    predrf = rf150.predict(test_X.reshape(test_X.shape[0],test_X.shape[2]))\n",
    "    cmrf = confusion_matrix(test_y.reshape(test_X.shape[0]),predrf)\n",
    "    accrf=sklearn.metrics.accuracy_score(test_y.reshape(test_X.shape[0]),predrf)\n",
    "    bacrf=sklearn.metrics.balanced_accuracy_score(test_y.reshape(test_X.shape[0]),predrf)\n",
    "    a.append(accrf)\n",
    "    b.append(bacrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-happiness",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-gossip",
   "metadata": {},
   "source": [
    "Development and compile the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-stopping",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelB1008 = Sequential()\n",
    "modelB1008.add(LSTM(150, input_shape=(1,56)))\n",
    "modelB1008.add(Dense(15, activation='relu'))\n",
    "modelB1008.add(Dense(5, activation='relu'))\n",
    "modelB1008.add(Dense(5, activation='relu'))\n",
    "modelB1008.add(Dense(3, activation='softmax'))\n",
    "modelB1008.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",metrics=[\"sparse_categorical_accuracy\"])\n",
    "modelB1008.summary()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "history50016 = modelB1008.fit(train_X, train_y, epochs=25, batch_size=16, \n",
    "                    validation_split=0.2, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-house",
   "metadata": {},
   "source": [
    "Make the predictions in testing set and print the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "predlstm = modelB1008.predict(test_X)\n",
    "predilstm = list()\n",
    "for i in range(predlstm.shape[0]):\n",
    "     max_value = max(list(predlstm[i]))\n",
    "     max_index = list(predlstm[i]).index(max_value)\n",
    "     predilstm.append(max_index)\n",
    "cmlstm = confusion_matrix(test_y,predilstm)\n",
    "cmlstm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-architect",
   "metadata": {},
   "source": [
    "Evaluate the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "accmlp=sklearn.metrics.accuracy_score(test_y.reshape(test_X.shape[0]),predilstm)\n",
    "bacmlp=sklearn.metrics.balanced_accuracy_score(test_y.reshape(test_X.shape[0]),predilstm)\n",
    "print(bacmlp), print(accmlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-offense",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-stock",
   "metadata": {},
   "source": [
    "The entire process. 20 replications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-running",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = list()\n",
    "b = list()\n",
    "for _ in range(20):\n",
    "    modelB1008 = Sequential()\n",
    "    modelB1008.add(LSTM(12, input_shape=(1,56)))\n",
    "#     modelB1008.add(Dense(15, activation='relu'))\n",
    "#     modelB1008.add(Dense(5, activation='relu'))\n",
    "#     modelB1008.add(Dense(5, activation='relu'))\n",
    "    modelB1008.add(Dense(3, activation='softmax'))\n",
    "    modelB1008.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",metrics=[\"sparse_categorical_accuracy\"])\n",
    "    modelB1008.summary()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "    history50016 = modelB1008.fit(train_X, train_y, epochs=25, batch_size=16, \n",
    "                    validation_split=0.2, verbose=1, shuffle=False)\n",
    "    predlstm = modelB1008.predict(test_X)\n",
    "    predilstm = list()\n",
    "    for i in range(predlstm.shape[0]):\n",
    "         max_value = max(list(predlstm[i]))\n",
    "         max_index = list(predlstm[i]).index(max_value)\n",
    "         predilstm.append(max_index)\n",
    "    cmlstm = confusion_matrix(test_y,predilstm)\n",
    "    cmlstm\n",
    "    accmlp=sklearn.metrics.accuracy_score(test_y.reshape(test_X.shape[0]),predilstm)\n",
    "    bacmlp=sklearn.metrics.balanced_accuracy_score(test_y.reshape(test_X.shape[0]),predilstm)\n",
    "    a.append(accmlp)\n",
    "    b.append(bacmlp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
